server:
  port: 8888



spring:
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    producer: # 生产者
      retries: 3 # 设置大于0的值，则客户端会将发送失败的记录重新发送
      batch-size: 16384
      buffer-memory: 33554432
      #      acks=0 把消息发送到kafka就认为发送成功
      #      acks=1 把消息发送到kafka leader分区，并且写入磁盘就认为发送成功
      #      acks=all 把消息发送到kafka leader分区，并且leader分区的副本follower对消息进行了同步就任务发送成功
      acks: 1
      # 指定消息key和消息体的编解码方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      group-id: mygroup
      enable-auto-commit: false
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      # 当每一条记录被消费者监听器（listenerconsumer）处理之后提交
      # record
      # 当每一批poll()的数据被消费者监听器（listenerconsumer）处理之后提交
      # batch
      # 当每一批poll()的数据被消费者监听器（listenerconsumer）处理之后，距离上次提交时间大于time时提交
      # time
      # 当每一批poll()的数据被消费者监听器（listenerconsumer）处理之后，被处理record数量大于等于count时提交
      # count
      # time |　count　有一个条件满足时提交
      # count_time
      # 当每一批poll()的数据被消费者监听器（listenerconsumer）处理之后, 手动调用acknowledgment.acknowledge()后提交
      # manual
      # 手动调用acknowledgment.acknowledge()后立即提交，一般使用这种
      # manual_immediate
      ack-mode: manual_immediate
      # 并行消费者数量
      concurrency: 1
  datasource:
    username: root
    password: 123456
    url: jdbc:mysql:///minhang?servertimezone=asia/shanghai
    hikari:
      auto-commit: true
      #空闲连接超时时长
      idle-timeout: 60000
      #连接超时时长
      connection-timeout: 60000
      #最大生命周期，0不过期
      max-lifetime: 0

mybatis-plus:
  mapper-locations: classpath:/mapper/*mapper.xml
  type-aliases-package: com.demo.entities
  configuration:
    map-underscore-to-camel-case: true
